"""
Voice Phishing Detection - Streamlit Frontend
Interactive UI for voice analysis and legal guidance
"""
import streamlit as st
import requests
import time
import json
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import os

# Page config
st.set_page_config(
    page_title="AI ë³´ì´ìŠ¤í”¼ì‹± íƒì§€ ì‹œìŠ¤í…œ",
    page_icon="ğŸ”’",
    layout="wide",
    initial_sidebar_state="expanded"
)

# API endpoint
API_URL = os.getenv("API_URL", "http://localhost:8001")

# Custom CSS
st.markdown("""
<style>
    .risk-low { 
        background-color: #d4edda; 
        padding: 20px; 
        border-radius: 10px; 
        border-left: 5px solid #28a745;
    }
    .risk-medium { 
        background-color: #fff3cd; 
        padding: 20px; 
        border-radius: 10px;
        border-left: 5px solid #ffc107;
    }
    .risk-high { 
        background-color: #f8d7da; 
        padding: 20px; 
        border-radius: 10px;
        border-left: 5px solid #dc3545;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
    }
    .source-card {
        background-color: #e9ecef;
        padding: 10px;
        border-radius: 5px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)


def main():
    # Sidebar
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/000000/security-checked.png", width=80)
        st.title("ğŸ”’ ë³´ì´ìŠ¤í”¼ì‹± íƒì§€")
        st.markdown("---")
        
        # Settings
        st.subheader("âš™ï¸ ì„¤ì •")
        model_type = st.selectbox(
            "íƒì§€ ëª¨ë¸",
            ["aasist", "rawnet2", "ecapa"],
            help="ìŒì„± ìœ„ë³€ì¡° íƒì§€ì— ì‚¬ìš©í•  AI ëª¨ë¸"
        )
        
        enable_watermark = st.checkbox(
            "ì›Œí„°ë§ˆí¬ íƒì§€ í™œì„±í™”",
            value=True,
            help="AI ìƒì„± ìŒì„±ì˜ ì›Œí„°ë§ˆí¬ íƒì§€"
        )
        
        st.markdown("---")
        
        # Info
        st.subheader("â„¹ï¸ ì •ë³´")
        st.markdown("""
        **ì§€ì› í˜•ì‹**: WAV, MP3, FLAC, OGG, M4A
        
        **íƒì§€ ëª¨ë¸**:
        - AASIST: ê·¸ë˜í”„ ì–´í…ì…˜ ê¸°ë°˜
        - RawNet2: End-to-End CNN
        - ECAPA: ìŠ¤í”¼ì»¤ ì„ë² ë”© í™œìš©
        
        **ì—°ë½ì²˜**:
        - ê²½ì°°ì²­: 112
        - ê¸ˆìœµê°ë…ì›: 1332
        """)
        
        st.markdown("---")
        st.caption(f"API: {API_URL}")

    # Main content
    st.title("ğŸ” AI ë³´ì´ìŠ¤í”¼ì‹± íƒì§€ ì‹œìŠ¤í…œ")
    st.markdown("ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ê°€ì§œ ìŒì„±(í•©ì„±/ë³€ì¡°)ì„ íƒì§€í•˜ê³ , ê´€ë ¨ ë²•ë¥  ì•ˆë‚´ë¥¼ ë°›ìœ¼ì„¸ìš”.")
    
    # Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ìŒì„± ë¶„ì„", "âš–ï¸ ë²•ë¥  ìƒë‹´", "ğŸ“Š ëŒ€ì‹œë³´ë“œ"])
    
    # Tab 1: Voice Analysis
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ“ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "ìŒì„± íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
                type=["wav", "mp3", "flac", "ogg", "m4a"],
                help="ìµœëŒ€ 60ì´ˆ ë¶„ëŸ‰ì˜ ìŒì„± íŒŒì¼"
            )
            
            if uploaded_file:
                st.audio(uploaded_file, format=f"audio/{uploaded_file.type.split('/')[-1]}")
                
                if st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                    with st.spinner("ìŒì„±ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        try:
                            # Call API
                            files = {"file": (uploaded_file.name, uploaded_file, uploaded_file.type)}
                            params = {
                                "model_type": model_type,
                                "enable_watermark": enable_watermark
                            }
                            
                            response = requests.post(
                                f"{API_URL}/api/v1/detect",
                                files=files,
                                params=params,
                                timeout=60
                            )
                            
                            if response.status_code == 200:
                                result = response.json()
                                st.session_state["detection_result"] = result
                                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                            else:
                                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {response.text}")
                                
                        except requests.exceptions.ConnectionError:
                            import traceback
                            traceback.print_exc()
                            st.error("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                            # Demo result for testing
                            st.session_state["detection_result"] = create_demo_result()
                            st.info("ë°ëª¨ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with col2:
            st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
            
            if "detection_result" in st.session_state:
                result = st.session_state["detection_result"]
                
                # Risk level display
                risk_level = result.get("risk_level", "MEDIUM")
                risk_label = result.get("risk_level_label", "ì¤‘ìœ„í—˜")
                risk_score = result.get("risk_score", 0.5)
                
                risk_class = f"risk-{risk_level.lower()}"
                emoji = {"LOW": "âœ…", "MEDIUM": "âš ï¸", "HIGH": "ğŸš¨"}.get(risk_level, "â“")
                st.markdown(f"""
                <div class="{risk_class}">
                    <h2>{emoji} <span style='color:black'>{risk_label}</span></h2>
                    <p><span style='color:black'><strong>ë¦¬ìŠ¤í¬ ì ìˆ˜:</strong> {risk_score:.1%}</span></p>
                    <p><span style='color:black'><strong>ê°€ì§œ ìŒì„± í™•ë¥ :</strong> {result.get('fake_probability', 0):.1%}</span></p>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown("---")
                
                # Metrics
                col_a, col_b, col_c = st.columns(3)
                
                with col_a:
                    st.metric(
                        "íƒì§€ ëª¨ë¸",
                        result.get("model_used", "N/A")
                    )
                
                with col_b:
                    wm = "ê°ì§€ë¨" if result.get("watermark_detected") else "ì—†ìŒ"
                    st.metric("ì›Œí„°ë§ˆí¬", wm)
                
                with col_c:
                    st.metric(
                        "ì²˜ë¦¬ ì‹œê°„",
                        f"{result.get('processing_time_ms', 0):.0f}ms"
                    )
                
                # Contributing factors
                st.markdown("### ğŸ“‹ ë¶„ì„ ìš”ì¸")
                for factor in result.get("contributing_factors", []):
                    severity = factor.get("severity", "LOW")
                    icon = {"LOW": "ğŸŸ¢", "MEDIUM": "ğŸŸ¡", "HIGH": "ğŸ”´"}.get(severity, "âšª")
                    st.markdown(f"{icon} **{factor.get('factor')}**: {factor.get('detail')}")
                
                # Recommendations
                st.markdown("### ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜")
                for rec in result.get("recommendations", []):
                    st.markdown(f"- {rec}")
                
                # Gauge chart
                fig = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=risk_score * 100,
                    domain={'x': [0, 1], 'y': [0, 1]},
                    title={'text': "ë¦¬ìŠ¤í¬ ì ìˆ˜"},
                    gauge={
                        'axis': {'range': [0, 100]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, 30], 'color': "#d4edda"},
                            {'range': [30, 70], 'color': "#fff3cd"},
                            {'range': [70, 100], 'color': "#f8d7da"}
                        ],
                        'threshold': {
                            'line': {'color': "red", 'width': 4},
                            'thickness': 0.75,
                            'value': risk_score * 100
                        }
                    }
                ))
                fig.update_layout(height=250)
                st.plotly_chart(fig, use_container_width=True)
            
            else:
                st.info("ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
    
    # Tab 2: Legal Query
    with tab2:
        st.subheader("âš–ï¸ ë²•ë¥  ìƒë‹´ AI")
        st.markdown("ë³´ì´ìŠ¤í”¼ì‹± ê´€ë ¨ ë²•ë¥  ë° ëŒ€ì‘ ë°©ë²•ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.")
        
        # Pre-defined questions
        quick_questions = [
            "ë³´ì´ìŠ¤í”¼ì‹± í”¼í•´ë¥¼ ë‹¹í–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
            "ë³´ì´ìŠ¤í”¼ì‹± ì‚¬ê¸°ì£„ì˜ í˜•ëŸ‰ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "í”¼í•´ê¸ˆ í™˜ê¸‰ ì ˆì°¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
            "ì§€ê¸‰ì •ì§€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
        ]
        
        st.markdown("**ë¹ ë¥¸ ì§ˆë¬¸:**")
        col_q1, col_q2 = st.columns(2)
        
        with col_q1:
            if st.button(quick_questions[0], use_container_width=True):
                st.session_state["legal_question"] = quick_questions[0]
            if st.button(quick_questions[2], use_container_width=True):
                st.session_state["legal_question"] = quick_questions[2]
        
        with col_q2:
            if st.button(quick_questions[1], use_container_width=True):
                st.session_state["legal_question"] = quick_questions[1]
            if st.button(quick_questions[3], use_container_width=True):
                st.session_state["legal_question"] = quick_questions[3]
        
        st.markdown("---")
        
        # Custom question
        question = st.text_area(
            "ì§ˆë¬¸ ì…ë ¥",
            value=st.session_state.get("legal_question", ""),
            height=100,
            placeholder="ì˜ˆ: ë³´ì´ìŠ¤í”¼ì‹± ë²”ì£„ìì˜ ì²˜ë²Œ ìˆ˜ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
        )
        
        # Risk context from detection
        risk_level = "MEDIUM"
        detection_summary = ""
        
        if "detection_result" in st.session_state:
            result = st.session_state["detection_result"]
            risk_level = result.get("risk_level", "MEDIUM")
            detection_summary = f"ê°€ì§œ ìŒì„± í™•ë¥  {result.get('fake_probability', 0):.1%}"
        
        if st.button("ğŸ“¤ ì§ˆë¬¸í•˜ê¸°", type="primary", disabled=len(question) < 5):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    response = requests.post(
                        f"{API_URL}/api/v1/legal-query",
                        json={
                            "question": question,
                            "risk_level": risk_level,
                            "detection_summary": detection_summary,
                            "top_k": 5
                        },
                        timeout=60
                    )
                    
                    if response.status_code == 200:
                        st.session_state["legal_response"] = response.json()
                    else:
                        st.error(f"ì˜¤ë¥˜: {response.text}")
                        
                except requests.exceptions.ConnectionError:
                    import traceback
                    traceback.print_exc()
                    st.error("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state["legal_response"] = create_demo_legal_response(question)
                    st.info("ë°ëª¨ ì‘ë‹µì„ í‘œì‹œí•©ë‹ˆë‹¤.")
        
        # Display response
        if "legal_response" in st.session_state:
            response = st.session_state["legal_response"]
            
            st.markdown("### ğŸ“œ ë‹µë³€")
            st.markdown(response.get("answer", ""))
            
            st.markdown("---")
            
            # Sources
            st.markdown("### ğŸ“š ì°¸ì¡° ë²•ë ¹")
            for source in response.get("sources", []):
                with st.expander(f"ğŸ“– {source.get('title', 'Unknown')}"):
                    st.markdown(f"**ì°¸ì¡° ë¬¸ì„œ:** {source.get('raw', 'N/A')}")
            
            # Metadata
            col_m1, col_m2 = st.columns(2)
            with col_m1:
                st.caption(f"í† í° ì‚¬ìš©ëŸ‰: {response.get('tokens_used', 0)}")
            with col_m2:
                st.caption(f"ì‘ë‹µ ì‹œê°„: {response.get('latency_ms', 0):.0f}ms")
    
    # Tab 3: Dashboard
    with tab3:
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ")
        
        # Fetch metrics
        try:
            response = requests.get(f"{API_URL}/api/v1/metrics", timeout=10)
            if response.status_code == 200:
                metrics = response.json()
            else:
                metrics = create_demo_metrics()
        except:
            metrics = create_demo_metrics()
        
        # Overview metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ì´ ìš”ì²­",
                metrics["requests"]["total"],
                delta=None
            )
        
        with col2:
            success_rate = metrics["requests"]["success_rate"] * 100
            st.metric(
                "ì„±ê³µë¥ ",
                f"{success_rate:.1f}%"
            )
        
        with col3:
            st.metric(
                "í‰ê·  ì‘ë‹µì‹œê°„",
                f"{metrics['latency']['total'].get('mean', 0):.0f}ms"
            )
        
        with col4:
            uptime_hours = metrics["uptime_seconds"] / 3600
            st.metric(
                "ê°€ë™ì‹œê°„",
                f"{uptime_hours:.1f}h"
            )
        
        st.markdown("---")
        
        # Charts
        col_chart1, col_chart2 = st.columns(2)
        
        with col_chart1:
            st.markdown("### ë¦¬ìŠ¤í¬ íƒì§€ ê²°ê³¼ ë¶„í¬")
            risk_data = metrics.get("risk_distribution", {"LOW": 0, "MEDIUM": 0, "HIGH": 0})
            
            fig = px.pie(
                values=list(risk_data.values()),
                names=["ì €ìœ„í—˜", "ì¤‘ìœ„í—˜", "ê³ ìœ„í—˜"],
                color_discrete_sequence=["#28a745", "#ffc107", "#dc3545"]
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col_chart2:
            st.markdown("### RAG ì‘ë‹µ ì‹œê°„ ë¶„í¬")
            latency = metrics.get("latency", {}).get("rag", {})
            
            fig = go.Figure(data=[
                go.Bar(
                    x=["í‰ê· ", "P50", "P95", "P99"],
                    y=[
                        latency.get("mean", 0),
                        latency.get("p50", 0),
                        latency.get("p95", 0),
                        latency.get("p99", 0)
                    ],
                    marker_color=["#007bff", "#17a2b8", "#ffc107", "#dc3545"]
                )
            ])
            fig.update_layout(yaxis_title="ë°€ë¦¬ì´ˆ(ms)")
            st.plotly_chart(fig, use_container_width=True)
        
        # Token usage
        st.markdown("### ğŸ’° í† í° ì‚¬ìš©ëŸ‰")
        tokens = metrics.get("tokens", {})
        col_t1, col_t2, col_t3, col_t4 = st.columns(4)
        
        with col_t1:
            st.metric("í‰ê· ", f"{tokens.get('mean', 0):.0f}")
        with col_t2:
            st.metric("P50", f"{tokens.get('p50', 0):.0f}")
        with col_t3:
            st.metric("P95", f"{tokens.get('p95', 0):.0f}")
        with col_t4:
            st.metric("P99", f"{tokens.get('p99', 0):.0f}")


def create_demo_result():
    """Create demo detection result"""
    import random
    
    fake_prob = random.uniform(0.3, 0.9)
    
    if fake_prob < 0.3:
        risk_level = "LOW"
        risk_label = "ì €ìœ„í—˜"
    elif fake_prob < 0.7:
        risk_level = "MEDIUM"
        risk_label = "ì¤‘ìœ„í—˜"
    else:
        risk_level = "HIGH"
        risk_label = "ê³ ìœ„í—˜"
    
    return {
        "request_id": "demo-123",
        "is_fake": fake_prob > 0.5,
        "fake_probability": fake_prob,
        "risk_level": risk_level,
        "risk_level_label": risk_label,
        "risk_score": fake_prob * 0.8,
        "watermark_detected": random.choice([True, False]),
        "watermark_confidence": random.uniform(0.1, 0.9),
        "model_used": "AASIST (Demo)",
        "recommendations": [
            "âš ï¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ìš”ì†Œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "í†µí™”ë¥¼ ì¢…ë£Œí•˜ê³  ê³µì‹ ëŒ€í‘œë²ˆí˜¸ë¡œ ì¬í™•ì¸í•˜ì„¸ìš”.",
            "ê¸ˆìœµê±°ë˜ë‚˜ ê°œì¸ì •ë³´ ì œê³µì„ ë³´ë¥˜í•˜ì„¸ìš”."
        ],
        "contributing_factors": [
            {
                "factor": "AI íƒì§€ ëª¨ë¸ ê²°ê³¼",
                "severity": "MEDIUM" if fake_prob < 0.7 else "HIGH",
                "detail": f"ê°€ì§œ ìŒì„± í™•ë¥  {fake_prob:.1%}ë¡œ íƒì§€ë¨"
            },
            {
                "factor": "ìŒí–¥ ì´ìƒ íŒ¨í„´",
                "severity": "LOW",
                "detail": "ì¼ë¶€ ë¹„ì •ìƒ ìŠ¤í™íŠ¸ëŸ¼ íŒ¨í„´ ê°ì§€"
            }
        ],
        "processing_time_ms": random.uniform(200, 800),
        "timestamp": datetime.now().isoformat()
    }


def create_demo_legal_response(question):
    """Create demo legal response"""
    return {
        "request_id": "demo-legal-123",
        "answer": f"""## ë³´ì´ìŠ¤í”¼ì‹± ëŒ€ì‘ ì•ˆë‚´

ì§ˆë¬¸: {question}

### ğŸ“Œ ê´€ë ¨ ë²•ë ¹

**[í˜•ë²• ì œ347ì¡° (ì‚¬ê¸°)]**
ì‚¬ëŒì„ ê¸°ë§í•˜ì—¬ ì¬ë¬¼ì˜ êµë¶€ë¥¼ ë°›ê±°ë‚˜ ì¬ì‚°ìƒì˜ ì´ìµì„ ì·¨ë“í•œ ìëŠ” 10ë…„ ì´í•˜ì˜ ì§•ì—­ ë˜ëŠ” 2ì²œë§Œì› ì´í•˜ì˜ ë²Œê¸ˆì— ì²˜í•©ë‹ˆë‹¤.

**[ì „ê¸°í†µì‹ ê¸ˆìœµì‚¬ê¸° íŠ¹ë³„ë²• ì œ3ì¡°]**
ê¸ˆìœµíšŒì‚¬ëŠ” í”¼í•´ìë¡œë¶€í„° í”¼í•´ ì‹ ê³ ë¥¼ ë°›ì€ ê²½ìš° ì¦‰ì‹œ í•´ë‹¹ ê³„ì¢Œì— ëŒ€í•œ ì§€ê¸‰ì •ì§€ ì¡°ì¹˜ë¥¼ í•´ì•¼ í•©ë‹ˆë‹¤.

### âœ… ê¶Œì¥ ì¡°ì¹˜

1. **ì¦‰ì‹œ ì‹ ê³ **: ê²½ì°°ì²­(112), ê¸ˆìœµê°ë…ì›(1332)
2. **ì§€ê¸‰ì •ì§€ ìš”ì²­**: ì†¡ê¸ˆ ê¸ˆìœµê¸°ê´€ ê³ ê°ì„¼í„°
3. **ì¦ê±° ë³´ì „**: í†µí™” ë…¹ìŒ, ë¬¸ì ìº¡ì²˜, ê±°ë˜ ë‚´ì—­ í™•ë³´
4. **í”¼í•´ í™˜ê¸‰ ì‹ ì²­**: ì±„ê¶Œì†Œë©¸ì ˆì°¨ ì™„ë£Œ í›„ ì‹ ì²­ ê°€ëŠ¥

### ğŸ“ ì—°ë½ì²˜
- ê²½ì°°ì²­ ì‚¬ì´ë²„ìˆ˜ì‚¬êµ­: 182
- ê¸ˆìœµê°ë…ì›: 1332
- í•œêµ­ì¸í„°ë„·ì§„í¥ì›: 118
""",
        "sources": [
            {"title": "í˜•ë²• ì œ347ì¡° (ì‚¬ê¸°)", "category": "criminal", "relevance_score": 0.95},
            {"title": "ì „ê¸°í†µì‹ ê¸ˆìœµì‚¬ê¸° íŠ¹ë³„ë²•", "category": "telecom_fraud", "relevance_score": 0.88},
            {"title": "ë³´ì´ìŠ¤í”¼ì‹± ëŒ€ì‘ ê°€ì´ë“œ", "category": "guide", "relevance_score": 0.82}
        ],
        "tokens_used": 850,
        "latency_ms": 1234,
        "timestamp": datetime.now().isoformat()
    }


def create_demo_metrics():
    """Create demo metrics"""
    return {
        "uptime_seconds": 3600,
        "requests": {
            "total": 150,
            "success": 145,
            "error": 5,
            "success_rate": 0.967
        },
        "latency": {
            "detection": {"mean": 350, "p50": 300, "p95": 600, "p99": 800},
            "rag": {"mean": 1200, "p50": 1000, "p95": 2000, "p99": 2500},
            "total": {"mean": 1550, "p50": 1300, "p95": 2600, "p99": 3300}
        },
        "tokens": {"mean": 800, "p50": 750, "p95": 1200, "p99": 1500},
        "risk_distribution": {"LOW": 45, "MEDIUM": 70, "HIGH": 35}
    }


if __name__ == "__main__":
    main()
